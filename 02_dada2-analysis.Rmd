---
title: "dada2-analysis"
output:
  github_document:
  toc: true
  toc_depht: 2
---

```{r}
library(knitr)
library(markdown) 
```


#chargement dada2package
```{r}
library("dada2")
library("ggplot2")
```

#Définir la variable de chemin pour qu'elle pointe vers le répertoire extrait sur du machine:
```{r}
path <- "~/MiSeq_SOP" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```

#lire les noms des fichiers fastq et effectuer quelques manipulations de chaînes pour obtenir des listes correspondantes des fichiers fastq avant et arrière.

```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```

#Visualiser les profils de qualité des lectures avant:

```{r}
plotQualityProfile(fnFs[1:2])
```


Dans l'image en niveaux de gris, il s'agit d'une carte thermique de la fréquence de chaque score de qualité à chaque emplacement de base. La ligne verte représente le score de qualité moyen pour chaque emplacement et la ligne orange représente le quartile de la distribution du score de qualité. La ligne rouge indique la proportion de lectures qui s'étendent au moins à cette position (ceci est plus utile pour les autres technologies de séquençage, car la longueur des lectures Illumina est généralement la même, donc la ligne plate rouge). La lecture prospective est de haute qualité. Nous recommandons généralement de couper le dernier nucléotide pour éviter d'éventuelles erreurs mal contrôlées. Ces profils de qualité ne recommandent pas de rognage supplémentaire. On va tronquer le front lu à la position 240 (couper les 10 derniers nucléotides)


#visualiser le profil de qualité des lectures inversées

```{r}
plotQualityProfile(fnRs[1:2])
```

La qualité des lectures inversées est nettement moins bonne, en particulier à la fin, ce qui est courant dans le séquençage Illumina. Ne vous inquiétez pas trop, car DADA2 incorpore des informations de qualité dans son modèle d'erreur, ce qui rend l'algorithme robuste aux séquences de qualité inférieure, mais trancher lorsque la qualité moyenne s'effondre augmentera la sensibilité de DADA2. Algorithmes avec des mutations de séquence rares. Sur la base de ces profils, nous tronquerons la lecture inverse à la position 160 où la distribution de masse est suspendue.

#Attribuez les noms de fichiers aux fichiers fastq.gz filtrés.

```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

les paramètres de filtrage standard: maxN=0(DADA2 ne nécessite aucun Ns) truncQ=2, rm.phix=TRUEet maxEE=2. Le maxEEparamètre définit le nombre maximum d '«erreurs attendues» autorisées dans une lecture, ce qui est un meilleur filtre que la simple moyenne des scores de qualité .

```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

#Apprentissage des erreurs
dada2 calcul un model d'erreur à partir des données, en alternant l'estimation des taux d'erreur et l'inférence de la composition de l'échantillon jusqu'à ce qu'ils convergent vers une solution cohérente conjointement. 
```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```

```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```

#Vérifier si rien d'autre, de visualiser les taux d'erreur estimés
```{r}
plotErrors(errF, nominalQ=TRUE)
```
Les points sont les taux d'erreur observés pour chaque score de qualité consensuel. La ligne noire montre les taux d'erreur estimés après convergence de l'algorithme d'apprentissage automatique. La ligne rouge montre les taux d'erreur attendus selon la définition nominale du Q-score. Ici, les taux d'erreur estimés (ligne noire) correspondent bien aux taux observés (points), et les taux d'erreur diminuent avec une qualité accrue comme prévu. Tout semble raisonnable et nous procédons en toute confiance

#Inférence d'échantillon

##appliquer l'algorithme d'inférence de l'échantillon de base aux données de séquence filtrées et découpées.
```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```

```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```

#Inspecter de l' dada-classobjet retourné
```{r}
dadaFs[[1]]
```
algorithme DADA2 a déduit 128 vraies variantes de séquence à partir des séquences uniques de 1979 dans le premier échantillon. L' dada-classobjet de retour est bien plus que cela (voir help("dada-class")pour quelques informations), y compris plusieurs diagnostics sur la qualité de chaque variante de séquence débruitée, mais cela dépasse la portée d'un didacticiel d'introduction.


#Fusionner les lectures appariées
#Alligner les R1 et R2 en un conti
```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```
L' mergersobjet est une liste de data.frames de chaque échantillon. Chacun data.framecontient le fusionné $sequence, son $abundanceet les indices des variantes de séquence $forwardet $reversequi ont été fusionnés. Les lectures appariées qui ne se chevauchaient pas exactement ont été supprimées mergePairs, réduisant encore davantage la sortie parasite.

#construction de table d'observation(amplicon sequence variant table), une version à plus haute résolution de la table OTU produite par des méthodes traditionnelles.
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
```{r}
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```
La table de séquence est une matrixavec des lignes correspondant aux (et nommées par) les échantillons, et des colonnes correspondant aux (et nommées par) les variantes de séquence. Ce tableau contient 293 ASV, et les longueurs de nos séquences fusionnées se situent toutes dans la plage attendue pour cet amplicon V4.

#Supprimer les chimères ou bien corrige les erreurs de substitution et d'indel, mais les chimères restent. Heureusement, la précision des variantes de séquence après le débruitage rend l'identification des ASV chimériques plus simple que lorsqu'il s'agit d'OTU floues

```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```


```{r}
sum(seqtab.nochim)/sum(seqtab)
```
```{r}
1-sum(seqtab.nochim)/sum(seqtab)
```
3,5 % de chimeres dans (n'utiliser pas les primers attention), la fréquence des séquences chimériques varie considérablement d'un ensemble de données à l'autre et dépend de facteurs tels que les procédures expérimentales et la complexité de l'échantillon. Ici, les chimères représentent environ 21% des variantes de séquence fusionnées, mais lorsque nous tenons compte de l'abondance de ces variantes, nous voyons qu'elles ne représentent qu'environ 4% des lectures de séquence fusionnée.

#Suivre les lectures dans le pipeline : examiner le nombre de lectures effectuées à chaque étape du pipeline:

#resume des filtres qualite
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```

#Attribuer une taxonomie aux variantes de séquence

##charger la base de donéées de silva
```{bash}
wget https://zenodo.org/record/3986799/files/silva_nr99_v138_train_set.fa.gz?
```


```{r}
dadaFs[[1]]
```


```{r}
taxa <- assignTaxonomy(seqtab.nochim, "~/silva_nr99_v138_train_set.fa.gz?", multithread=TRUE)
```


```{bash}
wget https://zenodo.org/record/3986799/files/silva_species_assignment_v138.fa.gz
```


#Inspectons les affectations taxonomiques

```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```
Sans surprise, les Bacteroidetes sont bien représentés parmi les taxons les plus abondants dans ces échantillons fécaux. Peu d'attributions d'espèces ont été faites, à la fois parce qu'il est souvent impossible de faire des assignations d'espèces sans ambiguïté à partir de sous-segments du gène 16S, et parce qu'il y a étonnamment peu de couverture du microbiote intestinal de souris indigène dans les bases de données de référence.


#Évaluation de la précision de DADA2 sur la communauté fictive :
```{r}
unqs.mock <- seqtab.nochim["Mock",]
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")
```

```{r}
mock.ref <- getSequences(file.path(path, "HMP_MOCK.v35.fasta"))
match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")
```
Cette fausse communauté contenait 20 souches bactériennes. DADA2 a identifié 20 ASV qui correspondent tous exactement aux génomes de référence des membres attendus de la communauté. Le taux d'erreur résiduel après le pipeline DADA2 pour cet échantillon est de 0%

```{r}
save.image (file = "02-dada2-analysis_space.RData")
```

